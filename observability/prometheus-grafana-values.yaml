# Prometheus and Grafana stack configuration (Workload Identity)
# Helm chart: prometheus-community/kube-prometheus-stack
# Install: helm upgrade --install prometheus prometheus-community/kube-prometheus-stack -n observability -f prometheus-grafana-values.yaml
#
# Prerequisites:
# 1. Create Grafana admin password secret:
#    kubectl create secret generic grafana-admin -n observability \
#      --from-literal=admin-user=admin \
#      --from-literal=admin-password='your-secure-password'
#
# 2. Run terraform apply to create managed identity and federated credentials
# 3. Get the client ID from terraform output: terraform output observability_identity_client_id
# 4. Update the client-id annotation below with the actual value

# Prometheus configuration
prometheus:
  enabled: true

  # Service Account with Workload Identity
  serviceAccount:
    create: true
    name: prometheus-kube-prometheus-prometheus
    annotations:
      # UPDATE THIS: Get value from terraform output observability_identity_client_id
      azure.workload.identity/client-id: "308ffb6c-c1fa-4047-8933-521942b7b4ce"

  prometheusSpec:
    retention: 15d           # Local retention (recent data for fast queries)
    retentionSize: 50GB

    # Run on Linux nodes only
    nodeSelector:
      kubernetes.io/os: linux

    # Pod label for Workload Identity
    podMetadata:
      labels:
        azure.workload.identity/use: "true"

    resources:
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 100m
        memory: 256Mi

    # Local storage for recent data and WAL
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: managed-csi
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi

    # Thanos sidecar disabled for demo - enable when Azure storage is configured
    # thanos:
    #   image: quay.io/thanos/thanos:v0.34.1
    #   objectStorageConfig:
    #     existingSecret:
    #       name: thanos-objstore-config
    #       key: objstore.yml

    # Scrape configs for demodeck services
    additionalScrapeConfigs:
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name

  # Thanos sidecar service disabled for demo
  thanosService:
    enabled: false

  thanosServiceMonitor:
    enabled: false

# Grafana configuration
grafana:
  enabled: true

  # Run on Linux nodes only
  nodeSelector:
    kubernetes.io/os: linux

  adminUser: admin
  # Use existing secret for password
  admin:
    existingSecret: grafana-admin
    userKey: admin-user
    passwordKey: admin-password

  persistence:
    enabled: true
    size: 5Gi
    storageClassName: managed-csi

  resources:
    limits:
      cpu: 200m
      memory: 256Mi
    requests:
      cpu: 50m
      memory: 128Mi

  # Datasources - Add Loki for log querying and Tempo for tracing
  additionalDataSources:
    - name: Loki
      type: loki
      url: http://loki-gateway.observability.svc.cluster.local:80
      access: proxy
      isDefault: false
      jsonData:
        maxLines: 1000

    # Tempo datasource for distributed tracing
    - name: Tempo
      type: tempo
      url: http://tempo.observability.svc.cluster.local:3200
      access: proxy
      isDefault: false
      jsonData:
        tracesToLogs:
          datasourceUid: loki
          tags: ['service.name']
          mappedTags: [{ key: 'service.name', value: 'service_name' }]
          filterByTraceID: true
          spanStartTimeShift: '-1h'
          spanEndTimeShift: '1h'
        nodeGraph:
          enabled: true
        lokiSearch:
          datasourceUid: loki

  # Dashboard providers - dashboards loaded via sidecar
  # Custom dashboards can be added as ConfigMaps with label grafana_dashboard=1

  # Grafana.ini configuration
  grafana.ini:
    server:
      root_url: "%(protocol)s://%(domain)s/"
    auth:
      disable_login_form: false
    analytics:
      reporting_enabled: false
      check_for_updates: false

  # Ingress for Grafana
  ingress:
    enabled: true
    ingressClassName: azure-application-gateway
    annotations:
      appgw.ingress.kubernetes.io/use-private-ip: "false"
    hosts:
      - grafana.k8s.demodeck.xyz
    path: /

  # Sidecar for dashboard loading
  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
      folder: /var/lib/grafana/dashboards
    datasources:
      enabled: true
      label: grafana_datasource

# Alertmanager configuration - disabled for demo to save resources
alertmanager:
  enabled: false

# Node exporters - for Linux nodes only
nodeExporter:
  enabled: true
  nodeSelector:
    kubernetes.io/os: linux

# Kube state metrics
kubeStateMetrics:
  enabled: true
  nodeSelector:
    kubernetes.io/os: linux

# Prometheus operator
prometheusOperator:
  enabled: true
  # Run on Linux nodes only
  nodeSelector:
    kubernetes.io/os: linux
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 50m
      memory: 64Mi

# Default rules
defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: false  # Managed by AKS
    general: true
    k8s: true
    kubeApiserverAvailability: true
    kubeApiserverBurnrate: true
    kubeApiserverHistogram: true
    kubeApiserverSlos: true
    kubelet: true
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    kubeScheduler: false  # Managed by AKS
    kubeStateMetrics: true
    network: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true
